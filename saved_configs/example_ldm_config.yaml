ldm:
  base_lr: 0.00001
  end_lr: 0.0000005
  warmup_lr: 0.0000001
  epochs_warmup: 5
  epochs_shift: 15
  type_lr: "constant"
  resolution: [128,96,128]
  params:
    buffer_interval: 50
    loss_type: "l1"
    scale_factor: 0.5
    ddpm:
      num_train_timesteps: 1000
      beta_schedule: "scaled_linear"
      beta_start: 0.0015
      beta_end: 0.0195
      prediction_type: "v_prediction"
    unet_config:
      params:
        spatial_dims: 3
        with_conditioning: True
        in_channels: 3
        out_channels: 3
        attention_levels:  [False, True, True]
        num_res_blocks: 2
        num_channels:  [64, 128, 256]
        num_head_channels: [64, 128, 256]
        resblock_updown: True
        transformer_num_layers: 1
        cross_attention_dim: 4
        norm_num_groups: 32

